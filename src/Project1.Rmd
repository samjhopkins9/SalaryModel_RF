<style>
        @font-face {
            font-family: 'Bebas Neue';
            src: url('../Fonts/BebasNeue-Regular.ttf') format('truetype');
        }

        @font-face {
            font-family: "Arsenal";
            src: url('../Fonts/Arsenal-Regular.ttf') format('truetype');
        }

        h1 {
          font-family: "Bebas Neue";
        }

        h2, h3, h4, h5, #names {
          font-family: 'Arsenal';
        }

        body, .r {
          background-color: #333;
          color: #ccc;
        }

        pre {
          background-color: #333 !important;
          color: #ddd !important;
        }
</style>
---
title: Predicting Salary
---
<p id="names">Sam Hopkins</p>

<h3>Initialize Workspace and Read Data</h3>
```{r}
rm(list = ls())
data <- read.csv("../data/salary_data.csv")
head(data)
summary(data)
```

<h2>Data Cleaning and Preparation</h2>
<h3>Remove NA values and assign 0 or 1 to gender</h3>
```{r}
print(sum(is.na(data)))
print(data[which(is.na(data), arr.ind = TRUE), ])
data <- na.omit(data)
data$GenderN <- 0
data$GenderN[data$Gender == "Male"] <- 1
```

<h3>Remove reduntant classes from education level and assign an integer 0-4</h3>
```{r}
unique(data$Education.Level)
data$EducationN[data$Education.Level == ""] <- 1
data$EducationN[data$Education.Level == "High School"] <- 1
data$EducationN[data$Education.Level == "Bachelor's Degree" | data$Education.Level == "Bachelor's"] <- 2
data$EducationN[data$Education.Level == "Master's Degree" | data$Education.Level == "Master's"] <- 3
data$EducationN[data$Education.Level == "phD" | data$Education.Level == "PhD"] <- 4
unique(data$EducationN)
```

<h2>Data Inspection</h2>
<h3>Correlations</h3>
```{r}
library(corrplot)
corrplot(cor(data[, sapply(data, is.numeric)]), method="color")
data$GenderN = as.factor(data$GenderN)
data$EducationN = as.factor(data$EducationN)
```
<h3>Histograms</h3>
```{r}
hist(data$Salary, main="Salary", breaks=100)
```

<h4>By Gender</h4>
```{r}
hist(data$Salary[data$GenderN == 1], main="Men", breaks=100)
hist(data$Salary[data$GenderN == 0], main="Women", breaks=100)
```

<h4>By Education Level</h4>
```{r}
hist(data$Salary[data$EducationN == 1], main="High School/None", breaks=100)
hist(data$Salary[data$EducationN == 2], main="Bachelor's", breaks=100)
hist(data$Salary[data$EducationN == 3], main="Master's", breaks=100)
hist(data$Salary[data$EducationN == 4], main="PhD", breaks=100)
```

<h3>Scatterplots</h3>
```{r}
plot(data$Age, data$Salary, main="Age vs Salary",xlab="Age", ylab="Salary")
plot(data$Years.of.Experience, data$Salary, main="Years of Experience vs Salary", xlab="Years of Experience", ylab="Salary")
```
<br>

<h3>Split data into training and testing 80/20</h3>
```{r}
splitData <- function(){

    set.seed(1)
    assign("indices", sample(1:nrow(data), as.integer(0.8*nrow(data))), envir=.GlobalEnv)
    assign("Training", data[indices, ], envir=.GlobalEnv)
    assign("Testing", data[-indices, ], envir=.GlobalEnv)
    assign("observed", Testing$Salary, envir=.GlobalEnv)

}
splitData()
```

<h3>Initialize vectors for later comparison</h3>
```{r}
R2s <- c()
RSEs <- c()
forms <- c()
methods <- c()
models <- list()
m <- 1
```

<h3>Define functions for modeling</h3>
```{r}
library(rpart)
library(rpart.plot)
library(randomForest)
library(glmnet)
library(caret)

evaluateModel <- function(model, ridge = FALSE){
    if (!(ridge)){
        predicted <<- predict(model, newdata=Testing)
    } else {
        X <- as.matrix(Testing[, -which(names(Training) == "Salary" | names(Training) == "Gender" | names(Training) == "Education.Level" | names(Testing) == "Job.Title")])
        predicted <<- predict(model, newx=X)
    }

    SSE = sum((predicted-observed)^2)
    SST = sum((observed-mean(observed))^2)
    
    R2s <<- c(R2s, 1 - SSE/SST)
    RSEs <<- c(RSEs, sqrt(SSE / (length(predicted) - length(model$coefficients))))
    models[[m]] <<- model
    m <<- m + 1
    
    return(list(model, predicted, R2s[m-1], RSEs[m-1]))

}

```

<h2>Modeling using all variables, no interaction terms</h2>
<h3>Linear Regression</h3>
```{r}
# initialize formula
f0 <- "Salary~Age+Years.of.Experience+GenderN+EducationN"
linearModel <- evaluateModel(glm(as.formula(f0), data=Training))
forms <- c(forms, f0)
methods <- c(methods, "General Linear Model")
```

<h4>R^2: `r R2s[m-1]`</h4>
<h4>RSE: `r RSEs[m-1]`</h4>
```{r}
# summary(models[[m-1]])
```

<h3>Ridge Regression</h3>
```{r}
X <- as.matrix(Training[, -which(names(Training) == "Salary" | names(Training) == "Gender" | names(Training) == "Education.Level" | names(Training) == "Job.Title")])
ridgeModel <- evaluateModel(cv.glmnet(x=X, y=Training$Salary, data=Training, alpha=0, lambda=10^seq(-6, 6, by = 0.1)), TRUE)
forms <- c(forms, f0)
methods <- c(methods, "Ridge Regression")
```
<h4>R^2: `r R2s[m-1]`
<h4>RSE: `r RSEs[m-1]`</h4>
```{r}
# summary(models[[m-1]])
```

<h3>Decision Tree</h3>
```{r}
treeModel <- evaluateModel(rpart(as.formula(f0), data=Training))
forms <- c(forms, f0)
methods <- c(methods, "Decision Tree")

```

<h4>R^2: `r R2s[m-1]`</h4>
<h4>RSE: `r RSEs[m-1]`</h4>
```{r}
# summary(models[[m-1]])
```

<h3>Random Forest</h3>
```{r}
rfModel0 <- evaluateModel(randomForest(as.formula(f0), data=Training))
forms <- c(forms, f0)
methods <- c(methods, "Random Forest")

```

<h4>R^2: `r R2s[m-1]`</h4>
<h4>RSE: `r RSEs[m-1]`</h4>
```{r}
# importance(models[[m-1]])
```

<h2>Modeling using interaction terms and cross-validation</h2>
<h3>Create interaction terms and re-split data</h3>
```{r}
# Flatten numeric values (age and years of experience)
# since relationships appear to flatten out the higher x gets
data$rtAge <- (data$Age)^0.3
data$rtExp <- (data$Years.of.Experience)^0.3
data$eduExp <- as.numeric(data$EducationN) * (mean(data$Years.of.Experience)/2) + data$Years.of.Experience

splitData()
```

<h3>Models</h3>
```{r}
f1 <- "Salary~rtAge+Years.of.Experience+EducationN+GenderN"
f2 <- "Salary~Age+rtExp+EducationN+GenderN"
f <- "Salary~Age+Years.of.Experience+eduExp+GenderN"
crossVal <- trainControl(method="cv", number=5, verbose=FALSE)

rfModel <- evaluateModel(randomForest(as.formula(f1), data=Training))
forms <- c(forms, f1)
methods <- c(methods, "Random Forest")

rfModel <- evaluateModel(randomForest(as.formula(f2), data=Training))
forms <- c(forms, f2)
methods <- c(methods, "Random Forest")

rfModel <- evaluateModel(randomForest(as.formula(f), data=Training))
forms <- c(forms, f)
methods <- c(methods, "Random Forest")

crossValRF <- train(as.formula(f), data=Training, method="rf", trControl=crossVal)
bestModel <- evaluateModel(crossValRF)
forms <- c(forms, f)
methods <- c(methods, "CV Random Forest")

crossValRF <- train(as.formula(f0), data=Training, method="rf", trControl=crossVal)
bestModel <- evaluateModel(crossValRF)
forms <- c(forms, f0)
methods <- c(methods, "CV Random Forest")

crossValGLM <- train(as.formula(f0), data=Training, method="glm", trControl = crossVal)
cvGLM <- evaluateModel(crossValGLM)
forms <- c(forms, f0)
methods <- c(methods, "CV GLM")

crossValDT <- train(as.formula(f0), data=Training, method="rpart", trControl = crossVal)
cvDT <- evaluateModel(crossValDT)
forms <- c(forms, f0)
methods <- c(methods, "CV Decision Tree")

crossValRR <- train(as.formula(f0), data=Training, method="glmnet", trControl = crossVal, tuneGrid = expand.grid(.alpha=1, .lambda=10^seq(-6, 6, by = 0.1)))
cvRR <- evaluateModel(crossValRR)
forms <- c(forms, f0)
methods <- c(methods, "CV Ridge Regression")

```

<h3>Comparison Table</h3>
```{r, results='asis'}
library(knitr)
library(kableExtra)

results <- data.frame(
    methods,
    forms,
    R2s,
    RSEs
)

table <- kable(results, format = "html", align = "c") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE) %>%
  add_header_above(c(" " = 1, " " = 2, "Model Performance" = 1)) %>%
  row_spec(1:nrow(results), background = "#000") %>%
  row_spec(nrow(results)-3, extra_css = "background-color: #333; color: #ff0000;")

print(table)
```

<h3>Best Model: Predicted vs Observed</h3>
```{r}
predicted <- bestModel[[2]]
plot(observed, predicted, xlab="Observed", ylab="Predicted", main=paste(paste("RSE:", round(bestModel[[4]], 1)), paste("R^2:", round(bestModel[[3]], 4))))
abline(lm(predicted~observed), col="red")

plot(bestModel[[1]])
plot(bestModel[[1]]$finalModel)
plot(rfModel0[[1]])

summary(cvGLM[[1]])
summary(linearModel[[1]])

plot(cvDT[[1]])
plot(cvRR[[1]])

```
